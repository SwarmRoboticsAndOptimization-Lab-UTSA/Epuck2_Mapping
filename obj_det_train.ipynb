{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:59:53.735730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:59:53.735750: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "from tflite_support import metadata\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    'epuck_images',\n",
    "    'epuck_images',\n",
    "    ['epuck_2']\n",
    ")\n",
    "\n",
    "val_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    'epuck_images',\n",
    "    'epuck_images',\n",
    "    ['epuck_2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:34:43.228870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-29 13:34:43.229073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/elusis/Documents/Fall2023/obj_det_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-08-29 13:34:43.229362: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-29 13:34:43.230170: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "spec = model_spec.get('efficientdet_lite0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:34:50.604147: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - ETA: 0s - det_loss: 1.2474 - cls_loss: 0.6540 - box_loss: 0.0119 - reg_l2_loss: 0.0630 - loss: 1.3104 - learning_rate: 0.0065 - gradient_norm: 2.6240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:35:31.581193: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 47s 611ms/step - det_loss: 1.2341 - cls_loss: 0.6465 - box_loss: 0.0118 - reg_l2_loss: 0.0630 - loss: 1.2971 - learning_rate: 0.0065 - gradient_norm: 2.6114 - val_det_loss: 0.6321 - val_cls_loss: 0.3201 - val_box_loss: 0.0062 - val_reg_l2_loss: 0.0630 - val_loss: 0.6952\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 28s 584ms/step - det_loss: 0.6573 - cls_loss: 0.2943 - box_loss: 0.0073 - reg_l2_loss: 0.0630 - loss: 0.7203 - learning_rate: 0.0049 - gradient_norm: 2.2799 - val_det_loss: 0.4531 - val_cls_loss: 0.2369 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0631 - val_loss: 0.5161\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.5584 - cls_loss: 0.2745 - box_loss: 0.0057 - reg_l2_loss: 0.0631 - loss: 0.6215 - learning_rate: 0.0048 - gradient_norm: 3.0803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:36:29.692632: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 29s 590ms/step - det_loss: 0.5546 - cls_loss: 0.2734 - box_loss: 0.0056 - reg_l2_loss: 0.0631 - loss: 0.6177 - learning_rate: 0.0048 - gradient_norm: 3.0479 - val_det_loss: 0.5280 - val_cls_loss: 0.3119 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0631 - val_loss: 0.5911\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 28s 581ms/step - det_loss: 0.5117 - cls_loss: 0.2617 - box_loss: 0.0050 - reg_l2_loss: 0.0631 - loss: 0.5748 - learning_rate: 0.0046 - gradient_norm: 3.3740 - val_det_loss: 0.4002 - val_cls_loss: 0.2199 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0631 - val_loss: 0.4633\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.4342 - cls_loss: 0.2312 - box_loss: 0.0041 - reg_l2_loss: 0.0631 - loss: 0.4973 - learning_rate: 0.0043 - gradient_norm: 2.6928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:37:26.826573: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 38s 773ms/step - det_loss: 0.4338 - cls_loss: 0.2315 - box_loss: 0.0040 - reg_l2_loss: 0.0631 - loss: 0.4969 - learning_rate: 0.0043 - gradient_norm: 2.6807 - val_det_loss: 0.3756 - val_cls_loss: 0.2353 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0631 - val_loss: 0.4387\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3887 - cls_loss: 0.2212 - box_loss: 0.0034 - reg_l2_loss: 0.0631 - loss: 0.4518 - learning_rate: 0.0040 - gradient_norm: 2.4609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:38:04.380738: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 580ms/step - det_loss: 0.3881 - cls_loss: 0.2210 - box_loss: 0.0033 - reg_l2_loss: 0.0631 - loss: 0.4512 - learning_rate: 0.0040 - gradient_norm: 2.4437 - val_det_loss: 0.3633 - val_cls_loss: 0.2227 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0631 - val_loss: 0.4265\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 28s 582ms/step - det_loss: 0.3919 - cls_loss: 0.2170 - box_loss: 0.0035 - reg_l2_loss: 0.0631 - loss: 0.4550 - learning_rate: 0.0037 - gradient_norm: 2.2754 - val_det_loss: 0.3332 - val_cls_loss: 0.1927 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0631 - val_loss: 0.3963\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3656 - cls_loss: 0.2117 - box_loss: 0.0031 - reg_l2_loss: 0.0631 - loss: 0.4287 - learning_rate: 0.0033 - gradient_norm: 2.5207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:39:01.096456: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 580ms/step - det_loss: 0.3651 - cls_loss: 0.2115 - box_loss: 0.0031 - reg_l2_loss: 0.0631 - loss: 0.4282 - learning_rate: 0.0033 - gradient_norm: 2.5077 - val_det_loss: 0.3921 - val_cls_loss: 0.2456 - val_box_loss: 0.0029 - val_reg_l2_loss: 0.0631 - val_loss: 0.4553\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 28s 580ms/step - det_loss: 0.3535 - cls_loss: 0.2010 - box_loss: 0.0031 - reg_l2_loss: 0.0631 - loss: 0.4166 - learning_rate: 0.0029 - gradient_norm: 2.1177 - val_det_loss: 0.4148 - val_cls_loss: 0.2498 - val_box_loss: 0.0033 - val_reg_l2_loss: 0.0631 - val_loss: 0.4779\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3364 - cls_loss: 0.1965 - box_loss: 0.0028 - reg_l2_loss: 0.0631 - loss: 0.3995 - learning_rate: 0.0025 - gradient_norm: 2.0474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:39:57.768534: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 35s 727ms/step - det_loss: 0.3371 - cls_loss: 0.1963 - box_loss: 0.0028 - reg_l2_loss: 0.0631 - loss: 0.4003 - learning_rate: 0.0025 - gradient_norm: 2.0402 - val_det_loss: 0.3597 - val_cls_loss: 0.1978 - val_box_loss: 0.0032 - val_reg_l2_loss: 0.0631 - val_loss: 0.4228\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3345 - cls_loss: 0.1974 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3976 - learning_rate: 0.0021 - gradient_norm: 2.0741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:40:33.149173: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 583ms/step - det_loss: 0.3330 - cls_loss: 0.1971 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3961 - learning_rate: 0.0021 - gradient_norm: 2.0712 - val_det_loss: 0.3378 - val_cls_loss: 0.2053 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0631 - val_loss: 0.4010\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 29s 591ms/step - det_loss: 0.3252 - cls_loss: 0.1894 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3883 - learning_rate: 0.0017 - gradient_norm: 2.0509 - val_det_loss: 0.2913 - val_cls_loss: 0.1826 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0631 - val_loss: 0.3544\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3293 - cls_loss: 0.1927 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3924 - learning_rate: 0.0013 - gradient_norm: 1.7810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:41:30.458163: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 29s 589ms/step - det_loss: 0.3299 - cls_loss: 0.1931 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3930 - learning_rate: 0.0013 - gradient_norm: 1.8097 - val_det_loss: 0.3026 - val_cls_loss: 0.1841 - val_box_loss: 0.0024 - val_reg_l2_loss: 0.0631 - val_loss: 0.3657\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 28s 580ms/step - det_loss: 0.3275 - cls_loss: 0.1934 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3906 - learning_rate: 9.6641e-04 - gradient_norm: 1.9588 - val_det_loss: 0.2764 - val_cls_loss: 0.1730 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0631 - val_loss: 0.3395\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3366 - cls_loss: 0.2012 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3997 - learning_rate: 6.6564e-04 - gradient_norm: 2.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:42:27.565629: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 35s 723ms/step - det_loss: 0.3355 - cls_loss: 0.2009 - box_loss: 0.0027 - reg_l2_loss: 0.0631 - loss: 0.3986 - learning_rate: 6.6297e-04 - gradient_norm: 2.2110 - val_det_loss: 0.2915 - val_cls_loss: 0.1817 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0631 - val_loss: 0.3546\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3125 - cls_loss: 0.1876 - box_loss: 0.0025 - reg_l2_loss: 0.0631 - loss: 0.3756 - learning_rate: 4.1177e-04 - gradient_norm: 1.7639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:43:02.696379: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 581ms/step - det_loss: 0.3130 - cls_loss: 0.1877 - box_loss: 0.0025 - reg_l2_loss: 0.0631 - loss: 0.3761 - learning_rate: 4.0964e-04 - gradient_norm: 1.7526 - val_det_loss: 0.2751 - val_cls_loss: 0.1743 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0631 - val_loss: 0.3382\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 29s 588ms/step - det_loss: 0.3205 - cls_loss: 0.1909 - box_loss: 0.0026 - reg_l2_loss: 0.0631 - loss: 0.3836 - learning_rate: 2.1334e-04 - gradient_norm: 1.9848 - val_det_loss: 0.2761 - val_cls_loss: 0.1756 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0631 - val_loss: 0.3392\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.2898 - cls_loss: 0.1797 - box_loss: 0.0022 - reg_l2_loss: 0.0631 - loss: 0.3529 - learning_rate: 8.0296e-05 - gradient_norm: 1.6805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:43:59.760204: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 580ms/step - det_loss: 0.2890 - cls_loss: 0.1793 - box_loss: 0.0022 - reg_l2_loss: 0.0631 - loss: 0.3521 - learning_rate: 7.9400e-05 - gradient_norm: 1.6832 - val_det_loss: 0.2759 - val_cls_loss: 0.1754 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0631 - val_loss: 0.3390\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 29s 585ms/step - det_loss: 0.3146 - cls_loss: 0.1871 - box_loss: 0.0026 - reg_l2_loss: 0.0631 - loss: 0.3777 - learning_rate: 1.1492e-05 - gradient_norm: 1.9347 - val_det_loss: 0.2784 - val_cls_loss: 0.1764 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0631 - val_loss: 0.3415\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - ETA: 0s - det_loss: 0.3121 - cls_loss: 0.1883 - box_loss: 0.0025 - reg_l2_loss: 0.0631 - loss: 0.3752 - learning_rate: 1.1030e-05 - gradient_norm: 1.9005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:44:56.980745: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 36s 746ms/step - det_loss: 0.3110 - cls_loss: 0.1876 - box_loss: 0.0025 - reg_l2_loss: 0.0631 - loss: 0.3741 - learning_rate: 1.1464e-05 - gradient_norm: 1.9002 - val_det_loss: 0.2788 - val_cls_loss: 0.1769 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0631 - val_loss: 0.3419\n"
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, epochs=20, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:47:27.240604: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 8s 1s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.64952123,\n",
       " 'AP50': 0.9993364,\n",
       " 'AP75': 0.80172396,\n",
       " 'APs': 0.3156792,\n",
       " 'APm': 0.65946543,\n",
       " 'APl': -1.0,\n",
       " 'ARmax1': 0.10596364,\n",
       " 'ARmax10': 0.7256727,\n",
       " 'ARmax100': 0.7463273,\n",
       " 'ARs': 0.41162792,\n",
       " 'ARm': 0.7568114,\n",
       " 'ARl': -1.0,\n",
       " 'AP_/epuck_2': 0.64952123}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:57:25.341825: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2023-08-29 13:57:42.344247: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 13:57:47.420033: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-08-29 13:57:47.420071: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-08-29 13:57:47.420804: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpusnd5d0c\n",
      "2023-08-29 13:57:47.513474: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-08-29 13:57:47.513517: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpusnd5d0c\n",
      "2023-08-29 13:57:47.803713: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-08-29 13:57:49.235626: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpusnd5d0c\n",
      "2023-08-29 13:57:49.886076: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2465273 microseconds.\n",
      "2023-08-29 13:57:51.063584: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-29 13:57:52.278834: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
      "2023-08-29 13:58:25.611677: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir='epuck_detector_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load the trained TFLite model and define some visualization functions\n",
    "\n",
    "#@markdown This code comes from the TFLite Object Detection [Raspberry Pi sample](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi).\n",
    "\n",
    "import platform\n",
    "from typing import List, NamedTuple\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "\n",
    "Interpreter = tf.lite.Interpreter\n",
    "load_delegate = tf.lite.experimental.load_delegate\n",
    "\n",
    "# pylint: enable=g-import-not-at-top\n",
    "\n",
    "\n",
    "class ObjectDetectorOptions(NamedTuple):\n",
    "  \"\"\"A config to initialize an object detector.\"\"\"\n",
    "\n",
    "  enable_edgetpu: bool = False\n",
    "  \"\"\"Enable the model to run on EdgeTPU.\"\"\"\n",
    "\n",
    "  label_allow_list: List[str] = None\n",
    "  \"\"\"The optional allow list of labels.\"\"\"\n",
    "\n",
    "  label_deny_list: List[str] = None\n",
    "  \"\"\"The optional deny list of labels.\"\"\"\n",
    "\n",
    "  max_results: int = -1\n",
    "  \"\"\"The maximum number of top-scored detection results to return.\"\"\"\n",
    "\n",
    "  num_threads: int = 1\n",
    "  \"\"\"The number of CPU threads to be used.\"\"\"\n",
    "\n",
    "  score_threshold: float = 0.0\n",
    "  \"\"\"The score threshold of detection results to return.\"\"\"\n",
    "\n",
    "\n",
    "class Rect(NamedTuple):\n",
    "  \"\"\"A rectangle in 2D space.\"\"\"\n",
    "  left: float\n",
    "  top: float\n",
    "  right: float\n",
    "  bottom: float\n",
    "\n",
    "\n",
    "class Category(NamedTuple):\n",
    "  \"\"\"A result of a classification task.\"\"\"\n",
    "  label: str\n",
    "  score: float\n",
    "  index: int\n",
    "\n",
    "\n",
    "class Detection(NamedTuple):\n",
    "  \"\"\"A detected object as the result of an ObjectDetector.\"\"\"\n",
    "  bounding_box: Rect\n",
    "  categories: List[Category]\n",
    "\n",
    "\n",
    "def edgetpu_lib_name():\n",
    "  \"\"\"Returns the library name of EdgeTPU in the current platform.\"\"\"\n",
    "  return {\n",
    "      'Darwin': 'libedgetpu.1.dylib',\n",
    "      'Linux': 'libedgetpu.so.1',\n",
    "      'Windows': 'edgetpu.dll',\n",
    "  }.get(platform.system(), None)\n",
    "\n",
    "\n",
    "class ObjectDetector:\n",
    "  \"\"\"A wrapper class for a TFLite object detection model.\"\"\"\n",
    "\n",
    "  _OUTPUT_LOCATION_NAME = 'location'\n",
    "  _OUTPUT_CATEGORY_NAME = 'category'\n",
    "  _OUTPUT_SCORE_NAME = 'score'\n",
    "  _OUTPUT_NUMBER_NAME = 'number of detections'\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      model_path: str,\n",
    "      options: ObjectDetectorOptions = ObjectDetectorOptions()\n",
    "  ) -> None:\n",
    "    \"\"\"Initialize a TFLite object detection model.\n",
    "    Args:\n",
    "        model_path: Path to the TFLite model.\n",
    "        options: The config to initialize an object detector. (Optional)\n",
    "    Raises:\n",
    "        ValueError: If the TFLite model is invalid.\n",
    "        OSError: If the current OS isn't supported by EdgeTPU.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load metadata from model.\n",
    "    displayer = metadata.MetadataDisplayer.with_model_file(model_path)\n",
    "\n",
    "    # Save model metadata for preprocessing later.\n",
    "    model_metadata = json.loads(displayer.get_metadata_json())\n",
    "    process_units = model_metadata['subgraph_metadata'][0]['input_tensor_metadata'][0]['process_units']\n",
    "    mean = 0.0\n",
    "    std = 1.0\n",
    "    for option in process_units:\n",
    "      if option['options_type'] == 'NormalizationOptions':\n",
    "        mean = option['options']['mean'][0]\n",
    "        std = option['options']['std'][0]\n",
    "    self._mean = mean\n",
    "    self._std = std\n",
    "\n",
    "    # Load label list from metadata.\n",
    "    file_name = displayer.get_packed_associated_file_list()[0]\n",
    "    label_map_file = displayer.get_associated_file_buffer(file_name).decode()\n",
    "    label_list = list(filter(lambda x: len(x) > 0, label_map_file.splitlines()))\n",
    "    self._label_list = label_list\n",
    "\n",
    "    # Initialize TFLite model.\n",
    "    if options.enable_edgetpu:\n",
    "      if edgetpu_lib_name() is None:\n",
    "        raise OSError(\"The current OS isn't supported by Coral EdgeTPU.\")\n",
    "      interpreter = Interpreter(\n",
    "          model_path=model_path,\n",
    "          experimental_delegates=[load_delegate(edgetpu_lib_name())],\n",
    "          num_threads=options.num_threads)\n",
    "    else:\n",
    "      interpreter = Interpreter(\n",
    "          model_path=model_path, num_threads=options.num_threads)\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    input_detail = interpreter.get_input_details()[0]\n",
    "\n",
    "    # From TensorFlow 2.6, the order of the outputs become undefined.\n",
    "    # Therefore we need to sort the tensor indices of TFLite outputs and to know\n",
    "    # exactly the meaning of each output tensor. For example, if\n",
    "    # output indices are [601, 599, 598, 600], tensor names and indices aligned\n",
    "    # are:\n",
    "    #   - location: 598\n",
    "    #   - category: 599\n",
    "    #   - score: 600\n",
    "    #   - detection_count: 601\n",
    "    # because of the op's ports of TFLITE_DETECTION_POST_PROCESS\n",
    "    # (https://github.com/tensorflow/tensorflow/blob/a4fe268ea084e7d323133ed7b986e0ae259a2bc7/tensorflow/lite/kernels/detection_postprocess.cc#L47-L50).\n",
    "    sorted_output_indices = sorted(\n",
    "        [output['index'] for output in interpreter.get_output_details()])\n",
    "    self._output_indices = {\n",
    "        self._OUTPUT_LOCATION_NAME: sorted_output_indices[0],\n",
    "        self._OUTPUT_CATEGORY_NAME: sorted_output_indices[1],\n",
    "        self._OUTPUT_SCORE_NAME: sorted_output_indices[2],\n",
    "        self._OUTPUT_NUMBER_NAME: sorted_output_indices[3],\n",
    "    }\n",
    "\n",
    "    self._input_size = input_detail['shape'][2], input_detail['shape'][1]\n",
    "    self._is_quantized_input = input_detail['dtype'] == np.uint8\n",
    "    self._interpreter = interpreter\n",
    "    self._options = options\n",
    "\n",
    "  def detect(self, input_image: np.ndarray) -> List[Detection]:\n",
    "    \"\"\"Run detection on an input image.\n",
    "    Args:\n",
    "        input_image: A [height, width, 3] RGB image. Note that height and width\n",
    "          can be anything since the image will be immediately resized according\n",
    "          to the needs of the model within this function.\n",
    "    Returns:\n",
    "        A Person instance.\n",
    "    \"\"\"\n",
    "    image_height, image_width, _ = input_image.shape\n",
    "\n",
    "    input_tensor = self._preprocess(input_image)\n",
    "\n",
    "    self._set_input_tensor(input_tensor)\n",
    "    self._interpreter.invoke()\n",
    "\n",
    "    # Get all output details\n",
    "    boxes = self._get_output_tensor(self._OUTPUT_LOCATION_NAME)\n",
    "    classes = self._get_output_tensor(self._OUTPUT_CATEGORY_NAME)\n",
    "    scores = self._get_output_tensor(self._OUTPUT_SCORE_NAME)\n",
    "    count = int(self._get_output_tensor(self._OUTPUT_NUMBER_NAME))\n",
    "\n",
    "    return self._postprocess(boxes, classes, scores, count, image_width,\n",
    "                             image_height)\n",
    "\n",
    "  def _preprocess(self, input_image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Preprocess the input image as required by the TFLite model.\"\"\"\n",
    "\n",
    "    # Resize the input\n",
    "    input_tensor = cv2.resize(input_image, self._input_size)\n",
    "\n",
    "    # Normalize the input if it's a float model (aka. not quantized)\n",
    "    if not self._is_quantized_input:\n",
    "      input_tensor = (np.float32(input_tensor) - self._mean) / self._std\n",
    "\n",
    "    # Add batch dimension\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "  def _set_input_tensor(self, image):\n",
    "    \"\"\"Sets the input tensor.\"\"\"\n",
    "    tensor_index = self._interpreter.get_input_details()[0]['index']\n",
    "    input_tensor = self._interpreter.tensor(tensor_index)()[0]\n",
    "    input_tensor[:, :] = image\n",
    "\n",
    "  def _get_output_tensor(self, name):\n",
    "    \"\"\"Returns the output tensor at the given index.\"\"\"\n",
    "    output_index = self._output_indices[name]\n",
    "    tensor = np.squeeze(self._interpreter.get_tensor(output_index))\n",
    "    return tensor\n",
    "\n",
    "  def _postprocess(self, boxes: np.ndarray, classes: np.ndarray,\n",
    "                   scores: np.ndarray, count: int, image_width: int,\n",
    "                   image_height: int) -> List[Detection]:\n",
    "    \"\"\"Post-process the output of TFLite model into a list of Detection objects.\n",
    "    Args:\n",
    "        boxes: Bounding boxes of detected objects from the TFLite model.\n",
    "        classes: Class index of the detected objects from the TFLite model.\n",
    "        scores: Confidence scores of the detected objects from the TFLite model.\n",
    "        count: Number of detected objects from the TFLite model.\n",
    "        image_width: Width of the input image.\n",
    "        image_height: Height of the input image.\n",
    "    Returns:\n",
    "        A list of Detection objects detected by the TFLite model.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Parse the model output into a list of Detection entities.\n",
    "    for i in range(count):\n",
    "      if scores[i] >= self._options.score_threshold:\n",
    "        y_min, x_min, y_max, x_max = boxes[i]\n",
    "        bounding_box = Rect(\n",
    "            top=int(y_min * image_height),\n",
    "            left=int(x_min * image_width),\n",
    "            bottom=int(y_max * image_height),\n",
    "            right=int(x_max * image_width))\n",
    "        class_id = int(classes[i])\n",
    "        category = Category(\n",
    "            score=scores[i],\n",
    "            label=self._label_list[class_id],  # 0 is reserved for background\n",
    "            index=class_id)\n",
    "        result = Detection(bounding_box=bounding_box, categories=[category])\n",
    "        results.append(result)\n",
    "\n",
    "    # Sort detection results by score ascending\n",
    "    sorted_results = sorted(\n",
    "        results,\n",
    "        key=lambda detection: detection.categories[0].score,\n",
    "        reverse=True)\n",
    "\n",
    "    # Filter out detections in deny list\n",
    "    filtered_results = sorted_results\n",
    "    if self._options.label_deny_list is not None:\n",
    "      filtered_results = list(\n",
    "          filter(\n",
    "              lambda detection: detection.categories[0].label not in self.\n",
    "              _options.label_deny_list, filtered_results))\n",
    "\n",
    "    # Keep only detections in allow list\n",
    "    if self._options.label_allow_list is not None:\n",
    "      filtered_results = list(\n",
    "          filter(\n",
    "              lambda detection: detection.categories[0].label in self._options.\n",
    "              label_allow_list, filtered_results))\n",
    "\n",
    "    # Only return maximum of max_results detection.\n",
    "    if self._options.max_results > 0:\n",
    "      result_count = min(len(filtered_results), self._options.max_results)\n",
    "      filtered_results = filtered_results[:result_count]\n",
    "\n",
    "    return filtered_results\n",
    "\n",
    "\n",
    "_MARGIN = 10  # pixels\n",
    "_ROW_SIZE = 10  # pixels\n",
    "_FONT_SIZE = 1\n",
    "_FONT_THICKNESS = 1\n",
    "_TEXT_COLOR = (0, 0, 255)  # red\n",
    "\n",
    "\n",
    "def visualize(\n",
    "    image: np.ndarray,\n",
    "    detections: List[Detection],\n",
    ") -> np.ndarray:\n",
    "  \"\"\"Draws bounding boxes on the input image and return it.\n",
    "  Args:\n",
    "    image: The input RGB image.\n",
    "    detections: The list of all \"Detection\" entities to be visualize.\n",
    "  Returns:\n",
    "    Image with bounding boxes.\n",
    "  \"\"\"\n",
    "  for detection in detections:\n",
    "    # Draw bounding_box\n",
    "    start_point = detection.bounding_box.left, detection.bounding_box.top\n",
    "    end_point = detection.bounding_box.right, detection.bounding_box.bottom\n",
    "    cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
    "\n",
    "    # Draw label and score\n",
    "    category = detection.categories[0]\n",
    "    class_name = category.label\n",
    "    probability = round(category.score, 2)\n",
    "    result_text = class_name + ' (' + str(probability) + ')'\n",
    "    text_location = (_MARGIN + detection.bounding_box.left,\n",
    "                     _MARGIN + _ROW_SIZE + detection.bounding_box.top)\n",
    "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                _FONT_SIZE, _TEXT_COLOR, _FONT_THICKNESS)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Run object detection and show the detection results\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('Eulises Images/black_and_white_image111.jpg')\n",
    "\n",
    "# # Load the TFLite model\n",
    "options = ObjectDetectorOptions(\n",
    "      num_threads=4,\n",
    "      score_threshold=0.5,\n",
    ")\n",
    "detector = ObjectDetector(model_path='epuck_detector_model/model.tflite', options=options)\n",
    "\n",
    "# Run object detection estimation using the model.\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Draw keypoints and edges on input image\n",
    "image_np = visualize(img, detections)\n",
    "\n",
    "# Show the detection result\n",
    "cv2.imshow('img',image_np)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj_det_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
